import os, io
from dataclasses import dataclass
from typing import Dict, Tuple, List
import numpy as np
import cv2
from PIL import Image

# ======= Tunables (env-driven) =======
SNAPSHOT_SIZE           = int(os.getenv("SNAPSHOT_SIZE", "640"))
JPG_QUALITY             = int(os.getenv("JPG_QUALITY", "95"))
MIN_TRACK_AGE           = int(os.getenv("MIN_TRACK_AGE", "3"))

# NEW: tighter crop + quality guards
SNAPSHOT_MARGIN         = float(os.getenv("SNAPSHOT_MARGIN", "0.15"))  # was 0.50
SNAPSHOT_MIN_SIDE       = int(os.getenv("SNAPSHOT_MIN_SIDE", "32"))    # px; skip tiny boxes

# NEW: light unsharp mask when upscaling
SNAPSHOT_SHARPEN        = int(os.getenv("SNAPSHOT_SHARPEN", "1"))      # 0/1
SNAPSHOT_SHARPEN_AMOUNT = float(os.getenv("SNAPSHOT_SHARPEN_AMOUNT", "1.2"))
SNAPSHOT_SHARPEN_RADIUS = float(os.getenv("SNAPSHOT_SHARPEN_RADIUS", "1.0"))  # Gaussian sigma
SNAPSHOT_SHARPEN_THRESHOLD = int(os.getenv("SNAPSHOT_SHARPEN_THRESHOLD", "3"))

@dataclass
class BestRec:
    frame_idx: int
    bbox: Tuple[int,int,int,int]  # tlbr
    conf: float
    cls_id: int
    area: float
    center_dist: float
    age: int

class BestFrameKeeper:
    """
    Prefer larger area → higher conf → closer to center → earlier frame;
    Emit only if age ≥ MIN_TRACK_AGE and min side ≥ SNAPSHOT_MIN_SIDE.
    """
    def __init__(self, W: int, H: int):
        self.W, self.H = W, H
        self._best: Dict[int, BestRec] = {}

    def _score(self, bbox, conf):
        x1,y1,x2,y2 = bbox
        area = max(0,x2-x1)*max(0,y2-y1)
        cx,cy=(x1+x2)/2.0,(y1+y2)/2.0
        dx,dy=abs(cx-self.W/2),abs(cy-self.H/2)
        return area, (dx*dx+dy*dy)**0.5

    def consider(self, tid: int, frame_idx: int, bbox, conf: float, cls_id: int):
        area, cd = self._score(bbox, conf)
        cur = self._best.get(tid)
        if cur is None:
            self._best[tid] = BestRec(frame_idx, tuple(map(int,bbox)), float(conf), int(cls_id), area, cd, age=1); return
        cur.age += 1
        cand = BestRec(frame_idx, tuple(map(int,bbox)), float(conf), int(cls_id), area, cd, age=cur.age)
        better = (
            (cand.area > cur.area) or
            (cand.area == cur.area and cand.conf > cur.conf) or
            (cand.area == cur.area and cand.conf == cur.conf and cand.center_dist < cur.center_dist) or
            (cand.area == cur.area and cand.conf == cur.conf and cand.center_dist == cur.center_dist and cand.frame_idx < cur.frame_idx)
        )
        if better: self._best[tid] = cand

    def items_ready(self) -> List[Tuple[int, "BestRec"]]:
        out = []
        for tid, rec in self._best.items():
            if rec.age < MIN_TRACK_AGE: 
                continue
            x1,y1,x2,y2 = rec.bbox
            w, h = max(0, x2-x1), max(0, y2-y1)
            if min(w, h) < SNAPSHOT_MIN_SIDE:
                # Skip tiny objects that will be too pixelated at 640x640
                continue
            out.append((tid, rec))
        return out

def _expand_square(bbox, W, H, margin: float = SNAPSHOT_MARGIN):
    x1,y1,x2,y2 = bbox
    w,h = x2-x1, y2-y1
    side = max(w,h) * (1 + margin*2)
    cx,cy=(x1+x2)/2.0,(y1+y2)/2.0
    x1=int(max(0, cx-side/2)); y1=int(max(0, cy-side/2))
    x2=int(min(W, cx+side/2));  y2=int(min(H, cy+side/2))
    return x1,y1,x2,y2

def _unsharp(img_bgr: np.ndarray, amount=SNAPSHOT_SHARPEN_AMOUNT, radius=SNAPSHOT_SHARPEN_RADIUS, thr=SNAPSHOT_SHARPEN_THRESHOLD):
    # img_bgr: uint8
    if amount <= 0:
        return img_bgr
    blurred = cv2.GaussianBlur(img_bgr, (0,0), radius)
    # build mask where difference > threshold to avoid boosting noise
    diff = cv2.absdiff(img_bgr, blurred)
    if thr > 0:
        mask = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY) > thr
        mask = np.repeat(mask[:, :, None], 3, axis=2)
    else:
        mask = np.ones_like(img_bgr, dtype=bool)
    sharp = cv2.addWeighted(img_bgr, 1 + amount, blurred, -amount, 0)
    out = img_bgr.copy()
    out[mask] = sharp[mask]
    return np.clip(out, 0, 255).astype(np.uint8)

def _letterbox_640_qa(img_bgr: np.ndarray) -> np.ndarray:
    """
    Quality-aware letterbox to 640x640:
      - If scaling DOWN -> INTER_AREA
      - If scaling UP   -> INTER_CUBIC (+ optional light unsharp mask)
    """
    h,w = img_bgr.shape[:2]
    if h == 0 or w == 0:
        canvas = np.zeros((SNAPSHOT_SIZE,SNAPSHOT_SIZE,3),dtype=np.uint8)
        return canvas
    scale = min(SNAPSHOT_SIZE / float(w), SNAPSHOT_SIZE / float(h))
    nw, nh = max(1, int(round(w * scale))), max(1, int(round(h * scale)))
    interp = cv2.INTER_AREA if scale < 1.0 else cv2.INTER_CUBIC
    resized = cv2.resize(img_bgr, (nw, nh), interpolation=interp)
    if scale > 1.0 and SNAPSHOT_SHARPEN:
        resized = _unsharp(resized)
    canvas = np.zeros((SNAPSHOT_SIZE, SNAPSHOT_SIZE, 3), dtype=np.uint8)
    sx, sy = (SNAPSHOT_SIZE - nw)//2, (SNAPSHOT_SIZE - nh)//2
    canvas[sy:sy+nh, sx:sx+nw] = resized
    return canvas

def save_and_upload_snapshot(frame_bgr, bbox, s3, bucket, key):
    H,W = frame_bgr.shape[:2]
    x1,y1,x2,y2 = _expand_square(bbox, W, H, margin=SNAPSHOT_MARGIN)
    crop = frame_bgr[y1:y2, x1:x2].copy()
    if crop.size == 0:
        crop = frame_bgr
    boxed = _letterbox_640_qa(crop)

    # JPEG encode and upload
    img = Image.fromarray(cv2.cvtColor(boxed, cv2.COLOR_BGR2RGB))
    buf = io.BytesIO()
    img.save(buf, format="JPEG", quality=JPG_QUALITY, optimize=True)
    buf.seek(0)
    s3.put_object(Bucket=bucket, Key=key, Body=buf.getvalue(), ContentType="image/jpeg")

def build_snapshot_key(user_id, workspace_id, video_id, workspace_code, camera_code, track_id, offset_ms):
    tid = f"{int(track_id):06d}"
    off = f"{int(offset_ms):06d}"
    fname = f"{workspace_code}_{camera_code}_{tid}_{off}.jpg"
    return f"{user_id}/{workspace_id}/{video_id}/snapshots/{fname}"
